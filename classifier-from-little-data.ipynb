{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing: artificially increase dataset size\n",
    "# addition of rotated and scaled versions of original images\n",
    "# generated on the fly during training\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(374, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "img = load_img(\"data/train/cats/cat000.jpg\")\n",
    "x = img_to_array(img)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3))) # changed column order\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.7073 - accuracy: 0.5275 - val_loss: 0.6708 - val_accuracy: 0.5835\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.6648 - accuracy: 0.6145 - val_loss: 0.6565 - val_accuracy: 0.6215\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 26s 204ms/step - loss: 0.6381 - accuracy: 0.6370 - val_loss: 0.6027 - val_accuracy: 0.6810\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 0.6081 - accuracy: 0.6780 - val_loss: 0.5805 - val_accuracy: 0.7010\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.5840 - accuracy: 0.6965 - val_loss: 0.5982 - val_accuracy: 0.6760\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.5721 - accuracy: 0.7175 - val_loss: 0.5676 - val_accuracy: 0.7085\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.5621 - accuracy: 0.7150 - val_loss: 0.6056 - val_accuracy: 0.6860\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 0.5534 - accuracy: 0.7355 - val_loss: 0.5315 - val_accuracy: 0.7360\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.5324 - accuracy: 0.7450 - val_loss: 0.5213 - val_accuracy: 0.7470\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.5132 - accuracy: 0.7550 - val_loss: 0.5799 - val_accuracy: 0.7155\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.5208 - accuracy: 0.7570 - val_loss: 0.5432 - val_accuracy: 0.7505\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.4895 - accuracy: 0.7730 - val_loss: 0.5513 - val_accuracy: 0.7500\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.4964 - accuracy: 0.7750 - val_loss: 0.4918 - val_accuracy: 0.7595\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4759 - accuracy: 0.7805 - val_loss: 0.5078 - val_accuracy: 0.7570\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.4653 - accuracy: 0.7895 - val_loss: 0.4908 - val_accuracy: 0.7610\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.4741 - accuracy: 0.7815 - val_loss: 0.4682 - val_accuracy: 0.7735\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4825 - accuracy: 0.7890 - val_loss: 0.4889 - val_accuracy: 0.7735\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.4437 - accuracy: 0.7920 - val_loss: 0.5235 - val_accuracy: 0.7480\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4489 - accuracy: 0.7915 - val_loss: 0.5764 - val_accuracy: 0.7690\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.4564 - accuracy: 0.7995 - val_loss: 0.4870 - val_accuracy: 0.7690\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.4396 - accuracy: 0.8005 - val_loss: 0.5522 - val_accuracy: 0.7745\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 25s 200ms/step - loss: 0.4416 - accuracy: 0.8155 - val_loss: 0.5816 - val_accuracy: 0.7660\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4471 - accuracy: 0.8030 - val_loss: 0.5534 - val_accuracy: 0.7695\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4555 - accuracy: 0.8030 - val_loss: 0.5494 - val_accuracy: 0.7750\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4663 - accuracy: 0.7975 - val_loss: 0.6254 - val_accuracy: 0.7655\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 25s 198ms/step - loss: 0.4479 - accuracy: 0.7965 - val_loss: 0.5194 - val_accuracy: 0.7630\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4453 - accuracy: 0.8080 - val_loss: 0.6485 - val_accuracy: 0.7495\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 25s 199ms/step - loss: 0.4339 - accuracy: 0.8140 - val_loss: 0.6841 - val_accuracy: 0.7355\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 25s 204ms/step - loss: 0.4399 - accuracy: 0.8080 - val_loss: 0.6872 - val_accuracy: 0.7285\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.4524 - accuracy: 0.8075 - val_loss: 0.5017 - val_accuracy: 0.7810\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 25s 197ms/step - loss: 0.4368 - accuracy: 0.8195 - val_loss: 0.4858 - val_accuracy: 0.7870\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.4332 - accuracy: 0.8145 - val_loss: 0.4915 - val_accuracy: 0.7815\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4408 - accuracy: 0.8155 - val_loss: 0.5876 - val_accuracy: 0.7900\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 0.4588 - accuracy: 0.8060 - val_loss: 0.5903 - val_accuracy: 0.7675\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 0.4408 - accuracy: 0.8095 - val_loss: 0.6628 - val_accuracy: 0.7815\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 25s 196ms/step - loss: 0.4433 - accuracy: 0.8095 - val_loss: 0.5100 - val_accuracy: 0.7605\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 24s 196ms/step - loss: 0.4490 - accuracy: 0.8110 - val_loss: 0.5056 - val_accuracy: 0.7715\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4681 - accuracy: 0.8025 - val_loss: 0.6601 - val_accuracy: 0.7415\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4412 - accuracy: 0.8110 - val_loss: 0.5506 - val_accuracy: 0.7725\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4422 - accuracy: 0.8035 - val_loss: 0.4986 - val_accuracy: 0.7555\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4543 - accuracy: 0.8160 - val_loss: 0.5815 - val_accuracy: 0.7830\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.4451 - accuracy: 0.8090 - val_loss: 0.5348 - val_accuracy: 0.7865\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.4436 - accuracy: 0.8085 - val_loss: 0.7808 - val_accuracy: 0.7630\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4530 - accuracy: 0.8005 - val_loss: 0.5305 - val_accuracy: 0.7935\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 24s 194ms/step - loss: 0.4416 - accuracy: 0.8105 - val_loss: 0.5025 - val_accuracy: 0.8005\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4544 - accuracy: 0.8090 - val_loss: 0.5325 - val_accuracy: 0.7220\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4466 - accuracy: 0.8025 - val_loss: 0.5450 - val_accuracy: 0.7345\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4300 - accuracy: 0.8070 - val_loss: 0.5481 - val_accuracy: 0.7450\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4486 - accuracy: 0.8190 - val_loss: 0.5169 - val_accuracy: 0.7595\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 24s 195ms/step - loss: 0.4430 - accuracy: 0.8200 - val_loss: 0.6140 - val_accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=2000 // batch_size)\n",
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pre-trained model (VGG16)\n",
    "# https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3\n",
    "# get model up to last maxpool\n",
    "\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "model = applications.VGG16(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "        shuffle=False)  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "# the predict_generator method returns the output of a model, given\n",
    "# a generator that yields batches of numpy data\n",
    "bottleneck_features_train = model.predict(generator)\n",
    "# save the output as a Numpy array\n",
    "np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_validation = model.predict(generator)\n",
    "np.save('bottleneck_features_validation.npy', bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4, 4, 512)\n",
      "(2000, 4, 4, 512)\n",
      "(2000, 4, 4, 512)\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.8592 - accuracy: 0.6560 - val_loss: 0.4550 - val_accuracy: 0.7720\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.5204 - accuracy: 0.7610 - val_loss: 0.5239 - val_accuracy: 0.7735\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.4571 - accuracy: 0.7965 - val_loss: 0.3924 - val_accuracy: 0.8215\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.4011 - accuracy: 0.8260 - val_loss: 0.4563 - val_accuracy: 0.7960\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.3523 - accuracy: 0.8530 - val_loss: 0.3797 - val_accuracy: 0.8345\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.3086 - accuracy: 0.8710 - val_loss: 0.5573 - val_accuracy: 0.7925\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.2970 - accuracy: 0.8725 - val_loss: 0.5233 - val_accuracy: 0.8055\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.2788 - accuracy: 0.8835 - val_loss: 0.4409 - val_accuracy: 0.8335\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 1s 10ms/step - loss: 0.2482 - accuracy: 0.9060 - val_loss: 0.6848 - val_accuracy: 0.7925\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.2165 - accuracy: 0.9220 - val_loss: 0.5674 - val_accuracy: 0.8265\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1967 - accuracy: 0.9235 - val_loss: 0.5533 - val_accuracy: 0.8245\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1882 - accuracy: 0.9265 - val_loss: 0.5486 - val_accuracy: 0.8230\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1607 - accuracy: 0.9380 - val_loss: 0.6092 - val_accuracy: 0.8340\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1488 - accuracy: 0.9390 - val_loss: 0.6330 - val_accuracy: 0.8345\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1429 - accuracy: 0.9495 - val_loss: 0.6183 - val_accuracy: 0.8315\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1195 - accuracy: 0.9585 - val_loss: 0.7645 - val_accuracy: 0.8160\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.1132 - accuracy: 0.9545 - val_loss: 0.9501 - val_accuracy: 0.8100\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0978 - accuracy: 0.9580 - val_loss: 0.8413 - val_accuracy: 0.8095\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0998 - accuracy: 0.9655 - val_loss: 0.7195 - val_accuracy: 0.8345\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0850 - accuracy: 0.9670 - val_loss: 0.9517 - val_accuracy: 0.8205\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0921 - accuracy: 0.9655 - val_loss: 1.2434 - val_accuracy: 0.7875\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0772 - accuracy: 0.9740 - val_loss: 1.0024 - val_accuracy: 0.8310\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0800 - accuracy: 0.9755 - val_loss: 0.9316 - val_accuracy: 0.8230\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0679 - accuracy: 0.9755 - val_loss: 0.9339 - val_accuracy: 0.8295\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0611 - accuracy: 0.9790 - val_loss: 1.0876 - val_accuracy: 0.8250\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0715 - accuracy: 0.9750 - val_loss: 1.0462 - val_accuracy: 0.8270\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0682 - accuracy: 0.9760 - val_loss: 1.4346 - val_accuracy: 0.7880\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0472 - accuracy: 0.9830 - val_loss: 1.2896 - val_accuracy: 0.8195\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0538 - accuracy: 0.9825 - val_loss: 1.2211 - val_accuracy: 0.8230\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0461 - accuracy: 0.9825 - val_loss: 1.2348 - val_accuracy: 0.8235\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 1.2185 - val_accuracy: 0.8240\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0365 - accuracy: 0.9860 - val_loss: 1.1967 - val_accuracy: 0.8365\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0464 - accuracy: 0.9860 - val_loss: 1.3330 - val_accuracy: 0.8195\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0508 - accuracy: 0.9830 - val_loss: 1.2011 - val_accuracy: 0.8320\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 1.3417 - val_accuracy: 0.8295\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0442 - accuracy: 0.9865 - val_loss: 1.2724 - val_accuracy: 0.8305\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0279 - accuracy: 0.9920 - val_loss: 1.4017 - val_accuracy: 0.8280\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0389 - accuracy: 0.9850 - val_loss: 1.3201 - val_accuracy: 0.8265\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0297 - accuracy: 0.9880 - val_loss: 1.3693 - val_accuracy: 0.8290\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0364 - accuracy: 0.9895 - val_loss: 1.3487 - val_accuracy: 0.8295\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 1.3848 - val_accuracy: 0.8250\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 1.4850 - val_accuracy: 0.8290\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0222 - accuracy: 0.9920 - val_loss: 1.6184 - val_accuracy: 0.8235\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0236 - accuracy: 0.9945 - val_loss: 1.5220 - val_accuracy: 0.8335\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0295 - accuracy: 0.9900 - val_loss: 1.4826 - val_accuracy: 0.8215\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 1.7900 - val_accuracy: 0.8220\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0597 - accuracy: 0.9875 - val_loss: 1.7548 - val_accuracy: 0.8145\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 1.5041 - val_accuracy: 0.8310\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 1.8109 - val_accuracy: 0.8150\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.0265 - accuracy: 0.9920 - val_loss: 1.5659 - val_accuracy: 0.8335\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load('bottleneck_features_train.npy')\n",
    "print(train_data.shape)\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "train_labels = np.array([0] * 1000 + [1] * 1000)\n",
    "\n",
    "validation_data = np.load('bottleneck_features_validation.npy')\n",
    "print(validation_data.shape)\n",
    "validation_labels = np.array([0] * 1000 + [1] * 1000)\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(None, None, None, 512)\n"
     ]
    }
   ],
   "source": [
    "# fine-tuning\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(applications.VGG16(include_top=False))\n",
    "\n",
    "print(len(model.layers))\n",
    "print(model.output_shape)\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=(4,4,512)))#model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights('bottleneck_fc_model.h5')\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "model.add(top_model)\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:25]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 191s 2s/step - loss: 1.1621 - accuracy: 0.8795 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 191s 2s/step - loss: 1.0361 - accuracy: 0.8875 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 191s 2s/step - loss: 1.1412 - accuracy: 0.8730 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 191s 2s/step - loss: 1.1434 - accuracy: 0.8760 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 188s 2s/step - loss: 1.1226 - accuracy: 0.8895 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0473 - accuracy: 0.8780 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1089 - accuracy: 0.8800 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0844 - accuracy: 0.8700 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0968 - accuracy: 0.8845 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0982 - accuracy: 0.8795 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0449 - accuracy: 0.8825 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1012 - accuracy: 0.8735 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1097 - accuracy: 0.8935 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1055 - accuracy: 0.8800 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0956 - accuracy: 0.8780 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 186s 1s/step - loss: 1.1421 - accuracy: 0.8850 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 187s 1s/step - loss: 1.1750 - accuracy: 0.8800 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1460 - accuracy: 0.8760 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 0.9960 - accuracy: 0.8870 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0522 - accuracy: 0.8860 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1869 - accuracy: 0.8800 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0642 - accuracy: 0.8775 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1984 - accuracy: 0.8750 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1391 - accuracy: 0.8685 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.2295 - accuracy: 0.8800 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1105 - accuracy: 0.8770 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1521 - accuracy: 0.8780 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0601 - accuracy: 0.8820 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0316 - accuracy: 0.8805 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0745 - accuracy: 0.8740 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 0.9754 - accuracy: 0.8835 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1177 - accuracy: 0.8875 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0251 - accuracy: 0.8805 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 0.9958 - accuracy: 0.8810 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1076 - accuracy: 0.8870 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0234 - accuracy: 0.8805 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1750 - accuracy: 0.8840 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1201 - accuracy: 0.8700 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0575 - accuracy: 0.8815 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0865 - accuracy: 0.8770 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 0.9751 - accuracy: 0.8860 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 0.9972 - accuracy: 0.8825 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 0.9878 - accuracy: 0.8860 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0671 - accuracy: 0.8810 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0112 - accuracy: 0.8760 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0786 - accuracy: 0.8785 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0348 - accuracy: 0.8820 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.1586 - accuracy: 0.8805 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 1.0912 - accuracy: 0.8860 - val_loss: 1.4631 - val_accuracy: 0.8655\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 185s 1s/step - loss: 0.9981 - accuracy: 0.8870 - val_loss: 1.4631 - val_accuracy: 0.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f72fc1902e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "# fine-tune the model\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "    \n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=2000 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
